{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble\n",
    "- 보팅(Voting) : 같은 데이터 세트를 이용하고, 서로 다른 분류 알고리즘을 사용하여 최종 예측\n",
    "- 보팅의 유형 : 하드보팅(다수결) / 소프트 보팅(확률)\n",
    "- 하드보팅보다는 소프트 보팅이 예측성능이 상대적으로 우수하여 주로 사용\n",
    "-\n",
    "- 배깅(Bagging) : 데이터 샘플링을 통해 서브세트를 만들고, 같은 분류 알고리즘을 사용하여 최종 예측\n",
    "- 배깅의 유형 : Decison Tree를 기반으로 한 랜덤 포레스트(확률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SVN\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# 앙상블\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 전처리\n",
    "from sklearn.preprocessing   import LabelEncoder , OneHotEncoder , StandardScaler , MinMaxScaler , Binarizer \n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "\n",
    "# 평가지표\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve , roc_curve\n",
    "\n",
    "# pandas, numpy, seaborn, 시각화\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 결측값 시각화\n",
    "import missingno as ms\n",
    "%matplotlib inline\n",
    "\n",
    "# 경고문구\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# datasets\n",
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'C:\\\\Users\\\\ruby\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'} <class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer, type(cancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bunch type --> Dataframe type\n",
    "cancerDF = pd.DataFrame(cancer.data, \n",
    "                        columns = cancer.feature_names)\n",
    "cancerDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "# 앙상블을 위한 모델 만들기\n",
    "features, labels = cancer.data, cancer.target\n",
    "\n",
    "print(features)\n",
    "print(labels)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 구현을 위한 분류모델 4개 써보기(tree, logistic, knn, svm)\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy',\n",
    "                              random_state = 10)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "tree_pred = tree.predict(X_test)\n",
    "\n",
    "# Logistic\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic_pred = logistic.predict(X_test)\n",
    "\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 250)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "# SVM \n",
    "svm = SVC(probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree : 0.9210526315789473\n",
      "logistic : 0.9298245614035088\n",
      "knn : 0.8421052631578947\n",
      "svm : 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "print('tree :' ,     accuracy_score(y_test, tree_pred))\n",
    "print('logistic :' , accuracy_score(y_test, logistic_pred))\n",
    "print('knn :' ,      accuracy_score(y_test, knn_pred))\n",
    "print('svm :' ,      accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft voting : 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# soft voting 구현\n",
    "voting_clf = VotingClassifier(estimators = [('tree', tree),('logistic', logistic), ('knn', knn),('svm', svm)],\n",
    "                              weights = [1,1,1,1], \n",
    "                              voting = 'soft') \n",
    "voting_clf.fit(X_train, y_train)\n",
    "soft_voting_pred = voting_clf.predict(X_test)\n",
    "print('soft voting :' , accuracy_score(y_test, soft_voting_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization\n",
    "plt.figure()\n",
    "\n",
    "# x축이 없으므로 만들어 줘야함\n",
    "x = np.arange(5)\n",
    "plt.bar(x, height=[accuracy_score(y_test, tree_pred),\n",
    "                   accuracy_score(y_test, logistic_pred), \n",
    "                   accuracy_score(y_test, knn_pred), \n",
    "                   accuracy_score(y_test, svm_pred), \n",
    "                   accuracy_score(y_test, soft_voting_pred)],\n",
    "                   color = 'pink')\n",
    "\n",
    "plt.xticks(x, ['tree', 'logistic', 'knn', 'svm', 'soft'])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist data로 연습!(0~9의 손글씨체)\n",
    "mnist = load_digits()\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "[0 1 2 ... 8 9 8]\n",
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "# feature, label값 설정\n",
    "# 0 ~255의 숫자가 들어가는 1차원의 벡터 형식으로 만듦\n",
    "features, labels = mnist.data, mnist.target\n",
    "\n",
    "print(features)\n",
    "print(labels)\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능평가 확인을 위한 함수\n",
    "\n",
    "def metrics_evaluation(y_test, y_pred) :\n",
    "    print('정확도 : {}, 정밀도 : {}, 재현율 : {}, 조화평균 : {}, AUC : {}'\n",
    "          .format(accuracy_score(y_test, y_pred),\n",
    "                  precision_score(y_test, y_pred),\n",
    "                  recall_score(y_test, y_pred),\n",
    "                  f1_score(y_test, y_pred),\n",
    "                  roc_auc_score(y_test, y_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 객체 생성, 튜닝은 하고싶은대로 01)\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy',\n",
    "                            max_depth = 8,\n",
    "                            max_features = 32,\n",
    "                            random_state = 35)\n",
    "\n",
    "# 학습\n",
    "dt.fit(X_train, y_train)\n",
    "# 예측\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# KNN 객체 생성, 튜닝은 하고싶은대로 02)\n",
    "knn = KNeighborsClassifier(n_neighbors = 299)\n",
    "# 학습\n",
    "knn.fit(X_train, y_train)\n",
    "# 예측\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SVM 객체 생성, 튜닝은 하고싶은대로 03)\n",
    "svm = SVC(probability=True)\n",
    "# 학습\n",
    "svm.fit(X_train, y_train)\n",
    "# 예측\n",
    "svm_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : [9 9 0 2 4 5 7 4 7 2 4 5 7 5 9 6 1 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 1 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 2 6 3 6 6 6 8 4 6 0\n",
      " 6 6 2 1 6 3 1 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 2 7 5 4 0 9 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 4 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 3 4 5 0 3 9 0 8 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 2 4 1 5 3 4 2 0 6 9 3 1 0 0 7 4 4 4 3 9 5\n",
      " 3 4 9 2 8 2 4 4 7 2 7 1 0 8 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 9 2 6 2 1 4\n",
      " 4 2 8 0 7 2 7 2 6 4 0 9 0 5 0 3 3 9 0 2 7 0 1 2 2 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 0 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 6 1\n",
      " 9 6 1 8 7 9 9 7 9 2 1 5 2 5 9 6 1 2 9 0 7 3 0 7 8 4 5 8 4 7 8 4 5 6 6 9 5\n",
      " 4 5 8 6 1 7 3 9 7 8 1 7 8 4 9 2 5 8 6 6 3 6 4 9 6 7 3]\n",
      "predictt : [9 9 0 2 4 5 7 4 4 2 4 5 7 5 3 6 8 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 8 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 0 6 3 6 6 6 8 5 6 0\n",
      " 6 6 2 3 4 3 4 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 0 7 5 4 0 3 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 7 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 5 4 5 0 1 9 0 2 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 1 4 6 5 3 4 2 0 6 9 9 1 0 0 7 4 4 4 7 9 5\n",
      " 3 4 9 1 3 2 1 4 7 1 7 1 0 2 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 8 2 6 2 1 4\n",
      " 4 2 2 0 7 1 7 2 9 5 0 5 0 5 0 1 1 9 0 2 7 0 4 2 5 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 4 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 4 1\n",
      " 9 6 1 1 7 9 9 7 9 2 1 5 2 5 9 6 1 0 8 0 7 3 0 7 8 4 5 2 4 4 2 4 5 6 6 8 5\n",
      " 1 5 8 6 1 7 3 9 7 4 1 7 8 9 9 2 5 1 6 6 3 6 4 9 6 7 3]\n",
      "tree : 0.8694444444444445\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 정확도\n",
    "print('target :', y_test)\n",
    "print('predictt :', dt_pred)\n",
    "print('tree :' , accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : [9 9 0 2 4 5 7 4 7 2 4 5 7 5 9 6 1 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 1 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 2 6 3 6 6 6 8 4 6 0\n",
      " 6 6 2 1 6 3 1 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 2 7 5 4 0 9 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 4 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 3 4 5 0 3 9 0 8 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 2 4 1 5 3 4 2 0 6 9 3 1 0 0 7 4 4 4 3 9 5\n",
      " 3 4 9 2 8 2 4 4 7 2 7 1 0 8 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 9 2 6 2 1 4\n",
      " 4 2 8 0 7 2 7 2 6 4 0 9 0 5 0 3 3 9 0 2 7 0 1 2 2 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 0 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 6 1\n",
      " 9 6 1 8 7 9 9 7 9 2 1 5 2 5 9 6 1 2 9 0 7 3 0 7 8 4 5 8 4 7 8 4 5 6 6 9 5\n",
      " 4 5 8 6 1 7 3 9 7 8 1 7 8 4 9 2 5 8 6 6 3 6 4 9 6 7 3]\n",
      "predictt : [9 9 0 2 4 5 7 4 4 2 4 5 7 5 3 6 8 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 8 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 0 6 3 6 6 6 8 5 6 0\n",
      " 6 6 2 3 4 3 4 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 0 7 5 4 0 3 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 7 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 5 4 5 0 1 9 0 2 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 1 4 6 5 3 4 2 0 6 9 9 1 0 0 7 4 4 4 7 9 5\n",
      " 3 4 9 1 3 2 1 4 7 1 7 1 0 2 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 8 2 6 2 1 4\n",
      " 4 2 2 0 7 1 7 2 9 5 0 5 0 5 0 1 1 9 0 2 7 0 4 2 5 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 4 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 4 1\n",
      " 9 6 1 1 7 9 9 7 9 2 1 5 2 5 9 6 1 0 8 0 7 3 0 7 8 4 5 2 4 4 2 4 5 6 6 8 5\n",
      " 1 5 8 6 1 7 3 9 7 4 1 7 8 9 9 2 5 1 6 6 3 6 4 9 6 7 3]\n",
      "knn : 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "# KNN 정확도\n",
    "print('target :', y_test)\n",
    "print('predictt :', dt_pred)\n",
    "print('knn :' , accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target : [9 9 0 2 4 5 7 4 7 2 4 5 7 5 9 6 1 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 1 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 2 6 3 6 6 6 8 4 6 0\n",
      " 6 6 2 1 6 3 1 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 2 7 5 4 0 9 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 4 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 3 4 5 0 3 9 0 8 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 2 4 1 5 3 4 2 0 6 9 3 1 0 0 7 4 4 4 3 9 5\n",
      " 3 4 9 2 8 2 4 4 7 2 7 1 0 8 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 9 2 6 2 1 4\n",
      " 4 2 8 0 7 2 7 2 6 4 0 9 0 5 0 3 3 9 0 2 7 0 1 2 2 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 0 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 6 1\n",
      " 9 6 1 8 7 9 9 7 9 2 1 5 2 5 9 6 1 2 9 0 7 3 0 7 8 4 5 8 4 7 8 4 5 6 6 9 5\n",
      " 4 5 8 6 1 7 3 9 7 8 1 7 8 4 9 2 5 8 6 6 3 6 4 9 6 7 3]\n",
      "predictt : [9 9 0 2 4 5 7 4 4 2 4 5 7 5 3 6 8 1 5 2 8 7 6 6 6 7 0 2 8 3 0 9 3 9 5 5 3\n",
      " 6 3 6 8 1 5 2 0 4 8 3 7 4 1 5 5 1 4 8 8 7 3 9 6 3 5 4 0 6 3 6 6 6 8 5 6 0\n",
      " 6 6 2 3 4 3 4 3 3 1 1 4 0 5 5 4 1 7 0 0 8 7 4 0 7 5 4 0 3 3 4 5 7 2 5 5 5\n",
      " 2 1 3 2 0 1 7 7 3 2 1 9 6 0 7 0 7 5 0 7 6 0 2 8 2 0 7 6 5 4 5 0 1 9 0 2 0\n",
      " 3 6 8 1 4 1 8 9 0 0 6 2 2 7 5 9 1 4 6 5 3 4 2 0 6 9 9 1 0 0 7 4 4 4 7 9 5\n",
      " 3 4 9 1 3 2 1 4 7 1 7 1 0 2 3 8 6 9 9 0 3 1 5 3 8 0 6 8 6 2 9 8 2 6 2 1 4\n",
      " 4 2 2 0 7 1 7 2 9 5 0 5 0 5 0 1 1 9 0 2 7 0 4 2 5 7 3 2 0 2 2 5 1 2 6 7 0\n",
      " 5 9 3 5 2 2 6 4 7 9 4 0 9 4 8 7 0 9 1 0 7 1 6 0 5 9 9 6 8 7 4 2 7 1 0 4 1\n",
      " 9 6 1 1 7 9 9 7 9 2 1 5 2 5 9 6 1 0 8 0 7 3 0 7 8 4 5 2 4 4 2 4 5 6 6 8 5\n",
      " 1 5 8 6 1 7 3 9 7 4 1 7 8 9 9 2 5 1 6 6 3 6 4 9 6 7 3]\n",
      "svm : 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "# SVM 정확도\n",
    "print('target :', y_test)\n",
    "print('predictt :', dt_pred)\n",
    "print('svm :' , accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting : 0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "# hard voting : 같은 데이터로 서로다른 분류 알고리즘을 사용(다수결)\n",
    "voting_clf = VotingClassifier(estimators = [('tree', dt),('knn', knn),('svm', svm)], # 사용한 분류기를 튜플형식으로\n",
    "                              weights = [1,1,1], # 가중치를 1:1:1으로 줌\n",
    "                              voting = 'hard') # hard / soft\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "hard_voting_pred = voting_clf.predict(X_test)\n",
    "print('hard voting :' , accuracy_score(y_test, hard_voting_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft voting : 0.9388888888888889\n"
     ]
    }
   ],
   "source": [
    "# soft voting : 같은 데이터로 서로다른 분류 알고리즘을 사용(확률)\n",
    "voting_clf = VotingClassifier(estimators = [('tree', dt),('knn', knn),('svm', svm)], # 사용한 분류기를 튜플형식으로\n",
    "                              weights = [1,1,1], # 가중치를 1:1:1으로 줌\n",
    "                              voting = 'soft') # hard / soft\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "soft_voting_pred = voting_clf.predict(X_test)\n",
    "print('soft voting :' , accuracy_score(y_test, soft_voting_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree : 0.8694444444444445\n",
      "svm : 0.9916666666666667\n",
      "knn : 0.8555555555555555\n",
      "hard voting : 0.9611111111111111\n",
      "soft voting : 0.9388888888888889\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "print('tree :' , accuracy_score(y_test, dt_pred))\n",
    "print('svm :' , accuracy_score(y_test, svm_pred))\n",
    "print('knn :' , accuracy_score(y_test, knn_pred))\n",
    "print('hard voting :' , accuracy_score(y_test, hard_voting_pred))\n",
    "print('soft voting :' , accuracy_score(y_test, soft_voting_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# result visualization\n",
    "plt.figure()\n",
    "\n",
    "# x축이 없으므로 만들어 줘야함\n",
    "x = np.arange(5)\n",
    "plt.bar(x, height=[accuracy_score(y_test, dt_pred),\n",
    "                   accuracy_score(y_test, svm_pred), \n",
    "                   accuracy_score(y_test, knn_pred), \n",
    "                   accuracy_score(y_test, hard_voting_pred), \n",
    "                   accuracy_score(y_test, soft_voting_pred)],\n",
    "                   color = 'pink')\n",
    "\n",
    "plt.xticks(x, ['tree', 'svm', 'knn', 'hard', 'soft'])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
